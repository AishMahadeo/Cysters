# # -*- coding: utf-8 -*-
# """fightos-cnn-models.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/16Nky2NKSuTZxg9edN5DyR-BjWrgBL80F
# """

# # FightOS - PCOS detection Using ultrasound images.

# # import os
# # os.environ['KAGGLE_CONFIG_DIR'] = '/content'

# # !kaggle datasets download -d anaghachoudhari/pcos-detection-using-ultrasound-images

# # !unzip \*.zip && rm *.zip

# import tensorflow as tf

# directory= "C:/Users/Aishwarya/Downloads/archive/data/train"

# print(directory)

# import tensorflow as tf
# from tensorflow.keras.layers import Input, Dense, Flatten 
# from tensorflow.keras.models import Model
# from tensorflow.keras.applications.vgg16 import VGG16
# from tensorflow.keras.applications.vgg16 import preprocess_input
# from tensorflow.keras.preprocessing.image import ImageDataGenerator
# from tensorflow.keras.preprocessing import image_dataset_from_directory
# import cv2
# import numpy as np
# import os
# import pandas as pd

# train_ds=tf.keras.preprocessing.image_dataset_from_directory(
#     directory,
#     labels="inferred",
#     label_mode="binary",
#     class_names=None,
#     color_mode="rgb",
#     batch_size=32,
#     image_size=(224, 224),
#     shuffle=True,
#     seed=24,
#     validation_split=None,
#     subset=None,
#     interpolation="bilinear",
#     follow_links=True,
#     crop_to_aspect_ratio=False,
# )

# import matplotlib.pyplot as plt
# plt.figure(figsize=(10, 10))
# class_names = train_ds.class_names
# for images, labels in train_ds.take(2):
#     for i in range(32):
#         ax = plt.subplot(6, 6, i + 1)
#         plt.imshow(images[i].numpy().astype("uint8"))
#         plt.title(class_names[int(labels[i])])
#         plt.axis("off")

# """Augumentation

# """

# from tensorflow.keras.preprocessing.image import ImageDataGenerator
# # create generator
# datagen = ImageDataGenerator(rescale = 1./255,
#                              shear_range = 0.2,
#                              zoom_range = 0.2,
#                              horizontal_flip = True,
#                              vertical_flip=True,
#                              rotation_range=30,
#                              validation_split=0.3,
#                              fill_mode='nearest'
#                              )
# # prepare an iterators for each dataset
# train_it = datagen.flow_from_directory( directory, 
#                                        class_mode='categorical',
#                                        classes=['infected', 'notinfected'],
#                                        target_size=(224, 224),
#                                        batch_size=100,
#                                        subset='training',
#                                        seed=24)
# # prepare an iterators for each dataset
# val_it = datagen.flow_from_directory( directory, 
#                                        class_mode='categorical',
#                                        classes=['infected', 'notinfected'],
#                                        target_size=(224, 224),
#                                        batch_size=100,
#                                        subset='validation',
#                                        seed=24)

# batchX, batchy = train_it.next()
# print('Batch shape=%s, min=%.3f, max=%.3f' % (batchy.shape, batchy.min(), batchy.max()))
# print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))

# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
# from tensorflow.keras import Sequential

# """# Model 1"""

# model1 = Sequential()
# model1.add(Conv2D(10, (5,5),padding='valid',activation='relu',input_shape=(224,224,3)))
# model1.add(MaxPooling2D(pool_size=(4,4)))
# # REPEAT CONV AND POOLING layer 3 TIMES
# model1.add(Conv2D(12, (5,5),padding='valid',activation='relu'))
# model1.add(MaxPooling2D(pool_size=(4,4)))
# #model1.add(Conv2D(128, (5,5),padding='valid',activation='relu'))
# # model1.add(Conv2D(256, (5,5),padding='valid',activation='relu'))
# # model1.add(MaxPooling2D(pool_size=(4,4)))
# model1.add(Flatten())
# #model1.add(Dense(128,activation='relu'))
# #model1.add(Dense(64,activation='relu'))
# model1.add(Dense(2,activation='softmax'))

# model1.summary()

# from tensorflow.keras.losses import CategoricalCrossentropy
# model1.compile(
#   optimizer='adam',
#   loss=CategoricalCrossentropy(),
#   metrics=['accuracy'])

# history = model1.fit( 
#   train_it,
#   validation_data=val_it,
#   epochs=5)

# import matplotlib.pyplot as plt

# plt.plot(history.history['loss'])
# plt.plot(history.history['val_loss'])

# """# Model 2 

# final model
# """

# model2 = Sequential()
# model2.add(Conv2D(12, (6,6),padding='valid',activation='relu',input_shape=(224,224,3)))
# model2.add(MaxPooling2D(pool_size=(6,6)))
# model2.add(Conv2D(15, (5,5),padding='valid',activation='relu'))
# model2.add(MaxPooling2D(pool_size=(5,5)))
# model2.add(Conv2D(10, (3,3),padding='valid',activation='relu'))
# # model2.add(Conv2D(256, (5,5),padding='valid',activation='relu'))
# model2.add(MaxPooling2D(pool_size=(3,3)))
# model2.add(Flatten())
# #model2.add(Dense(128,activation='relu'))
# #model2.add(Dense(64,activation='relu'))
# model2.add(Dense(2,activation='softmax'))

# from tensorflow.keras.losses import CategoricalCrossentropy
# model2.compile(
#   optimizer='adam',
#   loss=CategoricalCrossentropy(),
#   metrics=['accuracy'])

# history = model2.fit( 
#   train_it,
#   validation_data=val_it,
#   epochs=8)

# import matplotlib.pyplot as plt

# plt.plot(history.history['loss'])
# plt.plot(history.history['val_loss'])

# """# Model 3

# """

# model3 = Sequential()
# model3.add(Conv2D(10, (5,5),padding='valid',activation='relu',input_shape=(224,224,3)))
# model3.add(MaxPooling2D(pool_size=(4,4)))
# model3.add(Conv2D(12, (5,5),padding='valid',activation='relu'))
# model3.add(MaxPooling2D(pool_size=(4,4)))
# model3.add(Conv2D(5, (3,3),padding='valid',activation='relu'))
# # model3.add(Conv2D(256, (5,5),padding='valid',activation='relu'))
# model3.add(MaxPooling2D(pool_size=(3,3)))
# model3.add(Flatten())
# #model3.add(Dense(128,activation='relu'))
# #model3.add(Dense(64,activation='relu'))
# model3.add(Dense(2,activation='softmax'))

# from tensorflow.keras.losses import CategoricalCrossentropy
# model3.compile(
#   optimizer='adam',
#   loss=CategoricalCrossentropy(),
#   metrics=['accuracy'])

# history = model3.fit( 
#   train_it,
#   validation_data=val_it,
#   epochs=6)

# import matplotlib.pyplot as plt

# plt.plot(history.history['loss'])
# plt.plot(history.history['val_loss'])

# """# Model 4"""

# model4 = Sequential()
# model4.add(Conv2D(12, (5,5),padding='valid',activation='relu',input_shape=(224,224,3)))
# model4.add(MaxPooling2D(pool_size=(4,4)))
# model4.add(Conv2D(10, (5,5),padding='valid',activation='relu'))
# model4.add(MaxPooling2D(pool_size=(4,4)))
# model4.add(Conv2D(8, (3,3),padding='valid',activation='relu'))
# # model4.add(Conv2D(256, (5,5),padding='valid',activation='relu'))
# model4.add(MaxPooling2D(pool_size=(3,3)))
# model4.add(Flatten())
# #model4.add(Dense(128,activation='relu'))
# #model4.add(Dense(64,activation='relu'))
# model4.add(Dense(2,activation='softmax'))

# from tensorflow.keras.losses import CategoricalCrossentropy
# model4.compile(
#   optimizer='adam',
#   loss=CategoricalCrossentropy(),
#   metrics=['accuracy'])

# history = model4.fit( 
#   train_it,
#   validation_data=val_it,
#   epochs=10)

# import matplotlib.pyplot as plt

# plt.plot(history.history['loss'])
# plt.plot(history.history['val_loss'])

# """# Model 5"""

# model5 = Sequential()
# model5.add(Conv2D(15, (5,5),padding='valid',activation='relu',input_shape=(224,224,3)))
# model5.add(MaxPooling2D(pool_size=(5,5)))
# model5.add(Conv2D(12, (4,4),padding='valid',activation='relu'))
# model5.add(MaxPooling2D(pool_size=(4,4)))
# model5.add(Conv2D(8, (3,3),padding='valid',activation='relu'))
# # model5.add(Conv2D(256, (5,5),padding='valid',activation='relu'))
# model5.add(MaxPooling2D(pool_size=(3,3)))
# model5.add(Flatten())
# #model5.add(Dense(128,activation='relu'))
# #model5.add(Dense(64,activation='relu'))
# model5.add(Dense(2,activation='softmax'))

# from tensorflow.keras.losses import CategoricalCrossentropy
# model5.compile(
#   optimizer='adam',
#   loss=CategoricalCrossentropy(),
#   metrics=['accuracy'])

# history = model5.fit( 
#   train_it,
#   validation_data=val_it,
#   epochs=7)

# import matplotlib.pyplot as plt

# plt.plot(history.history['loss'])
# plt.plot(history.history['val_loss'])

"""# Saving Model"""

# model2.save('model.h5')
import numpy as np
from tensorflow import keras
model = keras.models.load_model('model.h5')

from tensorflow.keras.preprocessing.image import load_img
# from keras.preprocessing.image import load_img
image = load_img("C:/Users/Aishwarya/Downloads/archive/data/test/notinfected/img3.jpg", target_size=(224, 224))
img = np.array(image)
img = img / 255.0
img = img.reshape(1,224,224,3)
prediction = model.predict(img)

type(prediction)

print(prediction)

l={"infected":prediction[0][0],"notinfected":prediction[0][1]}
def get_key(val):
    for key, value in l.items():
         if val == value:
             return key
 
    return "key doesn't exist"
#label[0][1]

j=prediction.max()
print(get_key(j))